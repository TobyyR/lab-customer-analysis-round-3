{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02fa0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7459c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/TobyyR/lab-customer-analysis-round-2/master/files_for_lab/csv_files/marketing_customer_analysis.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e5d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns =[\"unnamed:_0\"], axis = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead251ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb48984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ac7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b850e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df[df[\"state\"].isna()]\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd3b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = df[df[\"months_since_last_claim\"].isna()]\n",
    "dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0012be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = df[df[\"number_of_open_complaints\"].isna()]\n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvc = df[df[\"vehicle_class\"].isna()]\n",
    "dfvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvs = df[df[\"vehicle_size\"].isna()]\n",
    "dfvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab690bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvt = df[df[\"vehicle_type\"].isna()]\n",
    "dfvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cbd30d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset = [\"vehicle_type\", \"vehicle_size\", \"vehicle_class\", \"number_of_open_complaints\", \"months_since_last_claim\", \"response\", \"state\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b6da93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef064406",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"effective_to_date\"] = pd.to_datetime(df[\"effective_to_date\"], errors = \"coerce\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b98560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = pd.to_datetime(df['effective_to_date']).dt.month\n",
    "\n",
    "filtered_data = df[(df['effective_to_date'].dt.month >= 1) & (df['effective_to_date'].dt.month <= 3)]\n",
    "\n",
    "#if filtered_data.empty:\n",
    "#    filtered_data = df[(df['effective_to_date'].dt.month >= 1) & (df['effective_to_date'].dt.month <= 2)]\n",
    "\n",
    "filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.month.value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6868002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_counts = df['response'].value_counts()\n",
    "response_counts.plot(kind='bar', color=['skyblue', 'orange'])\n",
    "plt.title('total Number of Responses')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x = 'sales_channel', hue = 'response', data = df)\n",
    "plt.title('Response Rate by Sales Channel')\n",
    "plt.xlabel('Sales Channel')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Response')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "response_by_channel = df.groupby('sales_channel')['response'].value_counts(normalize=True) * 100\n",
    "response_by_channel.plot(kind='bar', color=['blue', 'orange'])\n",
    "plt.title('Response Rate by Sales Channel')\n",
    "plt.xlabel('Sales Channel')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='response', y='total_claim_amount', data=df)\n",
    "plt.title('Response Rate by Total Claim Amount')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Total Claim Amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='response', y='income', data=df)\n",
    "plt.title('Response Rate by Income')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9edd905",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lab customer analysis round 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types of columns\n",
    "numerical = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categoricals = df.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "print(\"\\nNumerical Columns:\", numerical)\n",
    "print(\"\\nCategorical Columns:\", categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for i, column in enumerate(numerical):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = df.select_dtypes(include=[np.number])\n",
    "categoricals = df.select_dtypes(include=[object])\n",
    "\n",
    "correlation_matrix = numerical.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", annot_kws={\"size\": 10})\n",
    "plt.title(\"Correlation Matrix of Numerical Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr_pairs = [(i, j) for i in range(correlation_matrix.shape[0]) for j in range(i+1, correlation_matrix.shape[0]) if abs(correlation_matrix.iloc[i, j]) > 0.9]\n",
    "high_corr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9141a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if high_corr_pairs:\n",
    "    # Drop one of the features from each highly correlated pair\n",
    "    for pair in high_corr_pairs:\n",
    "        feature1 = numerical.columns[pair[0]]\n",
    "        feature2 = numerical.columns[pair[1]]\n",
    "        print(f\"Features '{feature1}' and '{feature2}' have high correlation of {correlation_matrix.iloc[pair]}\")\n",
    "\n",
    "        # Drop the feature with the least importance\n",
    "        # Here, you can implement your logic to decide which feature to drop\n",
    "        # For demonstration, let's drop the feature with the lower mean correlation with other variables\n",
    "        mean_corr_feature1 = correlation_matrix[feature1].drop(feature1).abs().mean()\n",
    "        mean_corr_feature2 = correlation_matrix[feature2].drop(feature2).abs().mean()\n",
    "\n",
    "        if mean_corr_feature1 < mean_corr_feature2:\n",
    "            numerical.drop(columns=[feature1], inplace=True)\n",
    "            print(f\"Dropping '{feature1}'\")\n",
    "        else:\n",
    "            numerical.drop(columns=[feature2], inplace=True)\n",
    "            print(f\"Dropping '{feature2}'\")\n",
    "\n",
    "    print(\"\\nUpdated Numerical DataFrame after dropping highly correlated features:\")\n",
    "    print(numerical.head())\n",
    "else:\n",
    "    print(\"No pair of features have high correlation (> 0.9), so no features are dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lab customer analysis round 5 + 6 + 7 \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce2614e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "012efb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-y split\n",
    "X = df.drop(columns=['total_claim_amount'])  # Features\n",
    "y = df['total_claim_amount']  # Target\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_numerical_normalized = scaler.fit_transform(X.select_dtypes(include=np.number))\n",
    "\n",
    "# One Hot Encoding for categorical features\n",
    "X_categorical_encoded = pd.get_dummies(X.select_dtypes(include=object), drop_first=True)\n",
    "\n",
    "# Concatenate numerical and encoded categorical features\n",
    "X_processed = np.concatenate([X_numerical_normalized, X_categorical_encoded], axis=1)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply linear regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_lr = lr_model.predict(X_train)\n",
    "y_pred_test_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Model Validation for Linear Regression\n",
    "# Train R2\n",
    "r2_train_lr = r2_score(y_train, y_pred_train_lr)\n",
    "# Test R2\n",
    "r2_test_lr = r2_score(y_test, y_pred_test_lr)\n",
    "# Train MSE\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train_lr)\n",
    "# Test MSE\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test_lr)\n",
    "# Train RMSE\n",
    "rmse_train_lr = np.sqrt(mse_train_lr)\n",
    "# Test RMSE\n",
    "rmse_test_lr = np.sqrt(mse_test_lr)\n",
    "# Train MAE\n",
    "mae_train_lr = mean_absolute_error(y_train, y_pred_train_lr)\n",
    "# Test MAE\n",
    "mae_test_lr = mean_absolute_error(y_test, y_pred_test_lr)\n",
    "\n",
    "print(\"Linear Regression Model Validation Results:\")\n",
    "print(\"Train R2:\", r2_train_lr)\n",
    "print(\"Test R2:\", r2_test_lr)\n",
    "print(\"Train MSE:\", mse_train_lr)\n",
    "print(\"Test MSE:\", mse_test_lr)\n",
    "print(\"Train RMSE:\", rmse_train_lr)\n",
    "print(\"Test RMSE:\", rmse_test_lr)\n",
    "print(\"Train MAE:\", mae_train_lr)\n",
    "print(\"Test MAE:\", mae_test_lr)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Feature Scaling\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_numerical_minmax = scaler_minmax.fit_transform(X.select_dtypes(include=np.number))\n",
    "\n",
    "scaler_robust = RobustScaler()\n",
    "X_numerical_robust = scaler_robust.fit_transform(X.select_dtypes(include=np.number))\n",
    "\n",
    "\n",
    "# Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_numerical_minmax)  # Using MinMax scaled numerical features\n",
    "\n",
    "\n",
    "# Feature Selection using RFE\n",
    "lr_model_rfe = LinearRegression()\n",
    "rfe = RFE(lr_model_rfe, n_features_to_select=10)  # Select top 10 features\n",
    "X_rfe = rfe.fit_transform(X_processed, y)\n",
    "\n",
    "# Train-test split for each modified dataset\n",
    "X_train_minmax, X_test_minmax, _, _ = train_test_split(X_numerical_minmax, y, test_size=0.2, random_state=42)\n",
    "X_train_robust, X_test_robust, _, _ = train_test_split(X_numerical_robust, y, test_size=0.2, random_state=42)\n",
    "X_train_poly, X_test_poly, _, _ = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "X_train_rfe, X_test_rfe, _, _ = train_test_split(X_rfe, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models and evaluate them\n",
    "lr_models = {\n",
    "    \"Original\": lr_model,\n",
    "    \"MinMax Scaling\": LinearRegression().fit(X_train_minmax, y_train),\n",
    "    \"Robust Scaling\": LinearRegression().fit(X_train_robust, y_train),\n",
    "    \"Polynomial Features\": LinearRegression().fit(X_train_poly, y_train),\n",
    "    \"Feature Selection (RFE)\": LinearRegression().fit(X_train_rfe, y_train)\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "evaluation_results = {}\n",
    "for name, model in lr_models.items():\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    evaluation_results[name] = {\"Train R^2\": train_score, \"Test R^2\": test_score}\n",
    "\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3c35b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
